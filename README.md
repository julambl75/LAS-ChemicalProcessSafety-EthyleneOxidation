This repository contains supplememtary material for a submission to MAKE-2026 (Machine Learning and Knowledge Engineering for Knowledge-Grounded Semantic Agents).

We have conducted a study investigating the feasibility of using symbolic machine learning to detect failures in chemical processes. To address the lack of real-world failure data, we leveraged data generated from a
chemical process simulator. Our method builds on a state-of-the-art symbolic machine learning system called DisPLAS, capable of learning predictive models in the form of probabilistic rules from context-dependent
noisy examples. This system is a general-purpose symbolic learner, which makes our approach agnostic of any specific chemical process. We have evaluated it using a simulated ethylene oxidation process.
Experimental results show that symbolic machine learning can outperform baseline methods such as random forest and multilayer perceptron, while preserving interpretability through the generation of
compact, rule-based predictive models.

## Data

The data/ folder contains three files:
- component_order.csv: used by T_static to determine upstream components
- static.csv: data for T_static, to be split into train and validation
- dynamic.csv: data for T_dynamic, to be split into train and validation

## Learned Rules

The learned_rules/ folder contains one subdirectory for the static rules learned over the entire set of failures and process parameters, and one subdirectory for the dynamic rules learned over the "real-world" parameters, for the three different sets of failures considered in Table 2.

## Confusion Matrices

The confusion_matrices/ folder contains one subdirectory for each of the subsets of experiments considered. In each one, we provide the confusion matrices for the baselines and for our approach, along with a labels.txt file that contains the mapping from class indices to experiment labels. In particular, for our approach we include the confusion matrices from each probability level l (i.e., considering only the hypothesis rules with probability $p \geq l$). For reference, we also include the corresponding failure classification rules.

## Explainability of Baselines

The decision_trees/ folder contains decision trees taken from trained instances of the two baselines that are inherently explainable: RandomForest and AdaBoost. By default the maximum depths for models' decision trees are respectively 15 and 4. **Note:** each decision tree provided is just one of the 100 estimators used â€” the models' output class for a given set of process conditions is computed by combining the results from all estimators (hence, our ability to select more than one of the highest-probability failure classes predicted).

The rf_hypothesis_parameters/ folder contains the decision tree and confusion matrix obtained from RandomForest when restricting the process parameters to those that appear in the set of rules generated by our rule-based approach (m1_pv, m2_pv, e2_tti, m3_pv^) when considering nontrivial experiments. We also provide those that result from including all process parameters, and the "real-world" process parameters (default) for comparison.

^ in the paper, we included a slightly simplified process flowsheet that hides (pressure) sensor M3, and referred to M3.PV as K1.P2

## Table 2

The table_2_short_names/ folder contains a text file explaining the short names of Table 2 in detail.

## All Experiments

For transparency and completeness, the all_experiments/ folder contains the results from all the experiments we ran (and more) to generate Table 2.
